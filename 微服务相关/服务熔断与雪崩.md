# 服务雪崩、降级与熔断

## 服务雪崩

而此时，`Service A`的流量波动很大，流量经常会突然性增加！那么在这种情况下，就算`Service A`能扛得住请求，`Service B`和`Service C`未必能扛得住这突发的请求。
此时，如果`Service C`因为抗不住请求，变得不可用。那么`Service B`的请求也会阻塞，慢慢耗尽`Service B`的线程资源，`Service B`就会变得不可用。紧接着，`Service A`也会不可用，这一过程如下图所示

![img](https://img2018.cnblogs.com/blog/725429/201901/725429-20190130225824355-156743654.jpg)



如上图所示，一个服务失败，导致整条链路的服务都失败的情形，我们称之为服务雪崩。

服务熔断和服务降级可以视为解决服务雪崩的手段之一

## 服务熔断

服务熔断：当下游的服务因为某种原因突然**变得不可用**或**响应过慢**，上游服务为了保证自己整体服务的可用性，不再继续调用目标服务，直接返回，快速释放资源。如果目标服务情况好转则恢复调用。 

需要说明的是熔断其实是一个框架级的处理，那么这套熔断机制的设计，基本上业内用的是`断路器模式`

![img](https://img2018.cnblogs.com/blog/725429/201901/725429-20190130230717121-435467568.jpg)

- 最开始处于`closed`状态，一旦检测到错误到达一定阈值，便转为`open`状态；
- 这时候会有个 reset timeout，到了这个时间了，会转移到`half open`状态；
- 尝试放行一部分请求到后端，一旦检测成功便回归到`closed`状态，即恢复服务；

在Hystrix中，对应配置如下

```
//失败阈值的大小，默认为20
circuitBreaker.requestVolumeThreshold=20
//过多长时间，熔断器再次检测是否开启，默认为5000，即5s钟
circuitBreaker.sleepWindowInMilliseconds=5 
//错误率，默认50%
circuitBreaker.errorThresholdPercentage=50%
```



## 服务降级

那么，什么是服务降级呢？
这里有两种场景:

- 当下游的服务因为某种原因**响应过慢**，下游服务主动停掉一些不太重要的业务，释放出服务器资源，增加响应速度！
- 当下游的服务因为某种原因**不可用**，上游主动调用本地的一些降级逻辑，避免卡顿，迅速返回给用户！

其实乍看之下，很多人还是不懂熔断和降级的区别!

其实应该要这么理解:

- 服务降级有很多种降级方式！如开关降级、限流降级、熔断降级!
- 服务熔断属于降级方式的一种！

服务降级大多是属于一种业务级别的处理。

那接下来最关键的一个问题，哪些业务需要埋点？

一般有以下方法
**(1)简化执行流程**
自己梳理出核心业务流程和非核心业务流程。然后在非核心业务流程上加上开关，一旦发现系统扛不住，关掉开关，结束这些次要流程。

**(2)关闭次要功能**
一个微服务下肯定有很多功能，那自己区分出主要功能和次要功能。然后次要功能加上开关，需要降级的时候，把次要功能关了吧！

**(3)降低一致性**
假设，你在业务上发现执行流程没法简化了，愁啊！也没啥次要功能可以关了，桑心啊！那只能降低一致性了，即将核心业务流程的同步改异步，将强一致性改最终一致性！

**可是这些都是手动降级，有办法自动降级么？**
这里我摸着良心说，我们在生产上没弄自动降级！因为一般需要降级的场景，都是可以预见的，例如某某活动。假设，平时真的有突发事件，流量异常，也有监控系统发邮件通知，提醒我们去降级！
当然，这并不代表自动降级不能做，因此以下内容可以认为我在胡说八道，因为我在生产上没实践过，只是头脑大概想了下，如果让我来做自动降级我会怎么实现：

- (1)自己设一个阈值，例如几秒内失败多少次，就启动降级
- (2)自己做接口监控(有兴趣的可以了解一下Rxjava)，达到阈值就走推送逻辑。怎么推呢？比如你配置是放在git上，就用jgit去改配置中心的配置。如果配置放数据库，就用jdbc去改。
- (3)改完配置中心的配置后，应用就可以自动检测到配置的变化，进行降级！(这句不了解的，了解一下配置中心的热刷新功能)